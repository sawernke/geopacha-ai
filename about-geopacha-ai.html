<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>About GeoPACHA-AI — Vision Transformer Models for Archaeological Survey</title>
  <meta name="description" content="Learn about the Vision Transformer models and AI-assisted archaeological survey pipeline that powers GeoPACHA-AI.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css">
</head>
<body>

  <!-- Header -->
  <header class="site-header">
    <nav class="nav-inner">
      <a href="index.html" class="nav-logo">
        <img src="images/logos/GeoPACHA-AI_Logo.png" alt="GeoPACHA-AI">
      </a>
      <button class="nav-toggle" aria-label="Toggle navigation">
        <span></span><span></span><span></span>
      </button>
      <ul class="nav-links">
        <li><a href="index.html">Home</a></li>
        <li><a href="why-geopacha-ai.html">Why GeoPACHA-AI?</a></li>
        <li><a href="about-geopacha-ai.html">About GeoPACHA-AI</a></li>
        <li><a href="publications.html">Publications</a></li>
        <li><a href="funding.html">Funding</a></li>
        <li><a href="about.html">Team</a></li>
        <li><a href="https://geopacha.cas.vanderbilt.edu/login">Login</a></li>
      </ul>
    </nav>
  </header>

  <!-- Hero -->
  <section class="page-hero page-hero--image" style="background-image: url('images/heroes/NC_01.png');">
    <div class="container">
      <h1>About GeoPACHA-AI</h1>
      <p>Our Vision Transformer models and AI-assisted archaeological survey pipeline</p>
    </div>
  </section>

  <!-- Content Section -->
  <section class="section">
    <div class="container container--narrow">
      <div class="prose fade-in">
        <p>With GeoPACHA-AI, archaeologists and machine learning experts have teamed together to design and build a new Vision Transformer (ViT) foundation model (DeepAndes) from WorldView 2 and WorldView 3 high resolution multispectral satellite imagery, with potential applications in many areas of research, from the earth sciences to urban planning and disaster preparedness. We then fine-tuned DeepAndes with a range of human-labeled data, resulting in our archaeology-specific AI model, DeepAndesArch.</p>
      </div>

      <div class="prose fade-in">
        <p>Our AI framework includes both semantic segmentation models of agricultural field systems (including active and abandoned terrace complexes, for example) and object detection models for identifying features associated with human settlements, such as abandoned architectural structures (archaeological buildings) and features related to pastoralist settlements in the high puna grasslands. As a federated, collaborative effort, GeoPACHA-AI harnesses the regional and domain expertise of a network of archaeological experts and their teams. It builds on our prior efforts that used "brute force" (manual) imagery survey across eight survey zones and documented about 40,000 archaeological loci. Our teams are expanding on those findings by generating expertly-curated training datasets and vetting the results of the AI detections in an iterative process that will result in an order of magnitude greater coverage than was possible via brute force methods. This "expert-in-the-loop" approach is central to how we envision GeoPACHA-AI will bring high accuracy detections of archaeological loci across the Andes.</p>
      </div>
      <div class="prose fade-in">
        <p>The GeoPACHA-AI technology stack is built on two AI models: <a href="https://github.com/geopacha/DeepAndes">DeepAndes</a>, a Vision Transformer (ViT) model that we have created from the DINOv2 self-supervised framework, using a large sample (3 million image patches), and DeepAndesArch, a fine-tuned archaeology-specific model based on the training data inputs from our collaborating teams. We are now in the process of generating a revised DeepAndes foundation model (DeepAndesV2) based on <a href="https://ai.meta.com/dinov3/">DINOv3</a> and a larger sample of high resolution multispectral satellite imagery and environmental rasters. DeepAndesV2 is enabled by the supercomputing resources of <a href="https://www.olcf.ornl.gov/frontier/">Oak Ridge National Laboratory</a>. Both models and the resulting database will be shared with the archaeological research and conservation communities to support investigation and heritage management.</p>
      </div>
      <div class="">
        <figure class="figure figure--zoomable">
          <img src="images/diagrams/Model-Deployment-Pipeline.png" alt="GeoPACHA-AI Model Deployment Pipeline" loading="lazy">
          <figcaption>The GeoPACHA-AI model deployment pipeline</figcaption>
        </figure>
      </div>

      <div class="prose fade-in">
        <p>Deployment of DeepAndesArch then enables autonomous detection of a range of archaeological features over large areas of Andean South America. The GeoPACHA-AI platform enables international teams of archaeologists to systematically and efficiently audit these autonomous detections. We will then use these audited data to improve DeepAndesArch performance to human- or better-than-human sensitivity and specificity, for deployment over virtually all of the Andes—an area of about 2 million square kilometers in an area approximately coincident with the historic footprint of the Inka Empire.</p>
      </div>

      <div class="prose fade-in">
        <p>Our goal is to detect the visible relict architectural features, active and abandoned agricultural infrastructure (terrace and field systems) across this vast area for the archaeological research community and heritage management entities.</p>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="site-footer">
    <div class="container">
      <div class="footer-inner">
        <div class="footer-brand">
          <img src="images/logos/GeoPACHA-AI_Logo.png" alt="GeoPACHA-AI">
          <p>An international collaborative project developing AI models for continental-scale archaeological survey across the Andes.</p>
        </div>
        <div class="footer-nav">
          <h4>Project</h4>
          <ul>
            <li><a href="why-geopacha-ai.html">Why GeoPACHA-AI?</a></li>
            <li><a href="about-geopacha-ai.html">About GeoPACHA-AI</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="funding.html">Funding</a></li>
          </ul>
        </div>
        <div class="footer-nav">
          <h4>More</h4>
          <ul>
            <li><a href="about.html">Team</a></li>
            <li><a href="funding.html">Funding</a></li>
            <li><a href="privacy-policy.html">Privacy Policy</a></li>
          </ul>
        </div>
      </div>
      <div class="footer-bottom">
        <span>&copy; 2026 GeoPACHA-AI &middot; Vanderbilt University &amp; Brown University</span>
        <div class="footer-logos">
          <img src="images/logos/NSF_4-Color_bitmap_Logo.png" alt="NSF" loading="lazy">
          <img src="images/logos/neh_logo_horizsmall.jpg" alt="NEH" loading="lazy">
          <img src="images/logos/ACLSlogo-big.png" alt="ACLS" loading="lazy">
        </div>
      </div>
    </div>
  </footer>

  <script src="js/main.js"></script>
</body>
</html>
